{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cCAgw40DFk2"
      },
      "source": [
        "# Convolutional Neural Network (CNN) in PyTorch\n",
        "\n",
        "This neural network will be trained on the Mnist dataset using the CNN architecture. More info about CNN can be found [here](https://medium.com/@draj0718/convolutional-neural-networks-cnn-architectures-explained-716fb197b243). \n",
        "\n",
        "**We start by importing the key libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# importing the key libraries\n",
        "import torch\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch import nn,optim\n",
        "from torchvision import datasets,transforms\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import dataloader\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Downloading the Mnist Dataset\n",
        "\n",
        "We will use the **torchvision** module to load the Mnist training and testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# setting the device to cuda to use the GPU if available\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# we download the dataset and transform it to a tensor data type\n",
        "my_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "training_set = datasets.MNIST(root=\"data\",train=True,transform=my_transform,download=True)\n",
        "testing_set = datasets.MNIST(root=\"data\",train=False,transform=my_transform,download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Constructing our CNN class\n",
        "\n",
        "We will initialize all the layers using the **nn** module in PyTorch. We will also create a method for training and testing our network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxl1am1WC6hA",
        "outputId": "c5c360cb-f997-4127-c76b-2e4c1c3e143a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 141245834.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 28529367.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 44474041.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 9496774.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# constructing our CNN class\n",
        "class PyTeen(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(    # inititalizing the layers of our CNN model\n",
        "        nn.Conv2d(1,6,5,padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,stride=2),\n",
        "\n",
        "        nn.Conv2d(6,16,5,padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,stride=2),\n",
        "\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(400,120),\n",
        "        nn.Linear(120,84),\n",
        "        nn.Linear(84,10),\n",
        "\n",
        "    )\n",
        "    self.loss = nn.CrossEntropyLoss()\n",
        "    self.optimizer = optim.Adam(self.parameters())\n",
        "\n",
        "  def forward(self,input):\n",
        "    return(self.layers(input))\n",
        "\n",
        "  def predict(self,input):\n",
        "    with torch.no_grad():\n",
        "      pred = self.forward(input)\n",
        "      return(torch.argmax(pred,axis=-1))\n",
        "\n",
        "  def train(self,input,label):\n",
        "    self.optimizer.zero_grad()\n",
        "    pred = self.forward(input)\n",
        "    loss = self.loss(pred,label)\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    return(loss.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-gLYyySJwGo"
      },
      "source": [
        "### Training the network\n",
        "\n",
        "We will use the train method defined above to train the network. We will also increase the batch size during training which have been proven to improve accuracy and training speed. \n",
        "\n",
        "More information can be found in the paper: [Don’t decay the learning rate increase the batch size](https://arxiv.org/pdf/1711.00489.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk_oBa47JulG",
        "outputId": "5d7859e3-ad4e-4278-8217-c52c6d6c7523"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:09<00:00, 54.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 1 :  1656.5260076865088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:05<00:00, 57.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 2 :  859.9851211777423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:05<00:00, 56.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 3 :  752.7621782300994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:06<00:00, 56.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 4 :  690.1360576909501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:07<00:00, 55.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 5 :  661.1853302748641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:07<00:00, 55.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 6 :  626.3621089668013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:08<00:00, 54.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 7 :  610.7814251285745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:08<00:00, 54.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 8 :  595.1937870879192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:09<00:00, 53.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 9 :  587.08782794117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:08<00:00, 54.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 10 :  574.7119326794636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:07<00:00, 55.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 11 :  550.999776529381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:09<00:00, 53.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 12 :  546.6498277119827\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:09<00:00, 53.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 13 :  538.414248032379\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:10<00:00, 52.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 14 :  546.385848196107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [01:10<00:00, 53.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 15 :  536.0006253729807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [01:00<00:00, 31.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 16 :  240.26686949143186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [01:06<00:00, 28.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 17 :  242.10855500912294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [01:01<00:00, 30.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 18 :  237.47877365374006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [01:01<00:00, 30.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 19 :  239.77386128739454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [01:01<00:00, 30.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 20 :  240.2110546482727\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:55<00:00,  8.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 21 :  52.891840908676386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:54<00:00,  8.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 22 :  52.74673435278237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:54<00:00,  8.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 23 :  50.571865409612656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:56<00:00,  8.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 24 :  51.49283261690289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:55<00:00,  8.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 25 :  51.59818361699581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:55<00:00,  8.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 26 :  53.339092034846544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:55<00:00,  8.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 27 :  51.576456340029836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:55<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 28 :  51.32389880158007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:55<00:00,  8.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 29 :  51.32833299227059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:54<00:00,  8.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 30 :  51.07730234414339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#initializing our network\n",
        "network = PyTeen()\n",
        "network.to(torch.device(DEVICE))\n",
        "\n",
        "# training loop\n",
        "EPOCHS = 30\n",
        "for i in range(EPOCHS):\n",
        "  total_loss = 0\n",
        "  # changing batch size during training\n",
        "  if i < 15:\n",
        "    BATCH_SIZE = 16\n",
        "  elif i >=15 and i <20:\n",
        "    BATCH_SIZE = 32\n",
        "  else:\n",
        "    BATCH_SIZE = 128\n",
        "\n",
        "  training_loader = dataloader.DataLoader(training_set,batch_size=BATCH_SIZE, shuffle=True)\n",
        "  for input,label in tqdm(training_loader):\n",
        "    input = input.to(torch.device(DEVICE))\n",
        "    label = label.to(torch.device(DEVICE))\n",
        "    loss = network.train(input,label)\n",
        "    total_loss += loss\n",
        "  print(\"EPOCH:\", i+1,\": \",total_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw41XxiEvVPQ"
      },
      "source": [
        "### Evaluating the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2XSLbGlvip3",
        "outputId": "804032f5-87c8-45b1-96e2-decd2d2eeade"
      },
      "outputs": [],
      "source": [
        "# setting up our training and testing data\n",
        "BATCH_SIZE = 32\n",
        "testing_loader = dataloader.DataLoader(testing_set,batch_size=BATCH_SIZE,shuffle=False)\n",
        "\n",
        "\n",
        "# Evaluating our CNN model\n",
        "correct_pred = 0\n",
        "\n",
        "for input,label in tqdm(testing_loader):\n",
        "  input = input.to(torch.device(DEVICE))\n",
        "  label = label.to(torch.device(DEVICE))\n",
        "  pred = network.predict(input)\n",
        "  # finding accuracy of our network\n",
        "  for i in range(len(pred)):\n",
        "    if pred[i] == label[i]:\n",
        "      correct_pred += 1\n",
        "\n",
        "print('\\\\n',correct_pred/(len(testing_loader)*BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also may want to save the network if we get a good accuracy score. I obtained an accuracy score of 98.82% which was satisfactory. To improve the accuracy, we can look into implementing a better CNN architecture like ResNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCxCsJHkSuc7"
      },
      "outputs": [],
      "source": [
        "# saving our weights if we get a good accuracy\n",
        "torch.save(network.state_dict(),\"pyTeenConvotilt9882.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMi5ZZNMKQMq"
      },
      "source": [
        "### Creating our own numbers to test the network\n",
        "\n",
        "- We can use MSPaint\n",
        "- Save result as jpg (280 x 280)\n",
        "- Using opencv-python library to load the image\n",
        "- Display the image using plt.imshow()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "HIoWRq-QK2c8",
        "outputId": "cdaad45f-24fd-4988-dc6f-d7c530e2a41f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# re-initializing our network\n",
        "network = PyTeen()\n",
        "network.to(torch.device(DEVICE))\n",
        "network.load_state_dict(torch.load(\"/content/pyTeenConvo9882.pth\"))\n",
        "\n",
        "# img = cv.imread(\"canvas.jpg\",cv.IMREAD_GRAYSCALE)\n",
        "\n",
        "# scaling = cv.resize(img,(28,28))\n",
        "# my_img_processed = cv.bitwise_not(scaling)\n",
        "# print(type(my_img_processed))\n",
        "# plt.imshow(my_img_processed)\n",
        "# print(my_img_processed.shape, type(my_img_processed))\n",
        "\n",
        "# cv.imwrite('new.jpg',my_img_processed)\n",
        "\n",
        "new_img = Image.open(\"new.png\")\n",
        "plt.imshow(new_img)\n",
        "my_img_transform = transforms.Compose([transforms.Resize((28,28)),transforms.ToTensor()])\n",
        "\n",
        "input_img = my_transform(new_img).unsqueeze(0) # converting it to a batch\n",
        "\n",
        "print(network.predict(input_img))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
